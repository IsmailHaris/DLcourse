{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Practical_visualObjectDetection_YOLOv3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabienMoutarde/DLcourse/blob/master/Practical_visualObjectDetection_YOLOv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w5KSKmal7FtZ"
      },
      "source": [
        "# Visual Objects Detection with YOLO_v3\n",
        "\n",
        "YOLO_v3 is currently among the fastest Convolutional Neural Networks for visual objects detection. [To get more information about YOLO_v3, you should go to the official YOLO page of its creator Joseph Redmon: https://pjreddie.com/darknet/yolo/](https://pjreddie.com/darknet/yolo/). Note that the corresponding original implementation is written **in C language** within the [Darknet Open Source Neural Networks C library](https://pjreddie.com/darknet/)\n",
        "\n",
        "This notebook was adapted by Pr Fabien Moutarde from https://github.com/tugstugi/dl-colab-notebooks/blob/master/notebooks/YOLOv3_PyTorch.ipynb, which uses a [PyTorch port of YOLO_v3 by Ayoosh Kathuria](https://github.com/ayooshkathuria/pytorch-yolo-v3) to detect objects on a given image. Note that this PyTorch implementation of YOLO_v3 is probably slower than the original version compiled from C.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5zeVakzj96KN"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd-YQh3FF9je",
        "colab_type": "text"
      },
      "source": [
        "*Make sure the python package for **git** and **wget** are installed*, otherwise do it. If using conda, open (possibly as Administrator) an \"Anaconda Power Shell prompt\", and execute **conda install git** into it, then execute **pip install wget**.\n",
        "\n",
        "Also *make sure that the python package for **torch** is installed*, and otherwise install it.\n",
        "If using conda, open (possibly as Administrator) an \"Anaconda Power Shell prompt\", and execute **conda install pytorch** into it.\n",
        "\n",
        "Finally, *make sure that the python package for **opencv** is installed*, and otherwise install it.\n",
        "If using conda, open (possibly as Administrator) an \"Anaconda Power Shell prompt\", and execute **conda install opencv** into it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rftl8CweF9jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "print('Your python version: {}'.format(sys.version_info.major))\n",
        "# Uncomment lines below only if you need them:\n",
        "#  On Windows/Anaconda\n",
        "#!{sys.executable} -m pip install wget\n",
        "#!{sys.executable} -m conda install git opencv keras\n",
        "#!{sys.executable} -m conda install pytorch torchvision cudatoolkit=10.0 -c pytorch\n",
        "#\n",
        "#  WITHOUT Conda\n",
        "#!{sys.executable} -m pip install -U git wget opencv keras --user\n",
        "#!{sys.executable} -m pip install -U pytorch torchvision --user # TO BE ADAPTED DEPENDING ON Target&CUDA level\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ap5kDp1X69_s",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/ayooshkathuria/pytorch-yolo-v3.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # clone and install dependencies\n",
        "  !git clone  $git_repo_url\n",
        "  #!cd $project_name && pip install -q -r requirement.txt\n",
        "  \n",
        "import sys\n",
        "sys.path.append(project_name)\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "plt.rcParams[\"axes.grid\"] = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsS5x3JJF9jm",
        "colab_type": "text"
      },
      "source": [
        "### Check if pyTorch is accessing GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9Qcn8NjF9jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "cudaOK = torch.cuda.is_available()\n",
        "if cudaOK:\n",
        "    print(\"CUDA available from PyTorch == TRUE\")\n",
        "    print(torch.cuda.get_device_properties(0))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KEcjFp7U9aV6"
      },
      "source": [
        "## Download official YOLO_v3 pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KSl-69n98Kpc",
        "colab": {}
      },
      "source": [
        "#import wget\n",
        "if not exists('yolov3.weights'):\n",
        "  !wget -q https://pjreddie.com/media/files/yolov3.weights\n",
        "  #filename = wget.download(\"https://pjreddie.com/media/files/yolov3.weights\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wMxlaoWoBhHF"
      },
      "source": [
        "## Detect objects on a test image\n",
        "\n",
        "First, download a standard test image from internet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P6ETX8scB7oj",
        "colab": {}
      },
      "source": [
        "IMAGE_URL = 'https://raw.githubusercontent.com/tugstugi/dl-colab-notebooks/master/resources/dog.jpg'\n",
        "image_file = basename(IMAGE_URL)\n",
        "!wget -q -O $image_file $IMAGE_URL\n",
        "!ls\n",
        "image_name = basename(IMAGE_URL)\n",
        "\n",
        "#image_file = wget.download('https://raw.githubusercontent.com/tugstugi/dl-colab-notebooks/master/resources/dog.jpg')\n",
        "#plt.imshow(matplotlib.image.imread(image_file))\n",
        "#image_name = 'dog.jpg' \n",
        "\n",
        "plt.imshow(matplotlib.image.imread(image_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FRQu6AkbC9w-"
      },
      "source": [
        "Execute `detect.py` on that image and show the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RQZUaDTo8dvr",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "!cd pytorch-yolo-v3 && python detect.py --weights ../yolov3.weights --images ../$image_name --det ..\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(matplotlib.image.imread('det_%s' % image_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eALRcYY896Ki"
      },
      "source": [
        "### Now, try it on a real images from a camera on-board a car"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "etQV12_VGYBK",
        "colab": {}
      },
      "source": [
        "# Uncomment below ONLY IF RUNNING ON Colab, and if you need access to your GoogleDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-UPFCKFF9j6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy whatever image you want to test on, and display it\n",
        "\n",
        "image_file = 'example_front-imageREAL.png'\n",
        "\n",
        "# Uncomment below ONLY IF RUNNING ON Colab, and if the test image is on your GoogleDrive\n",
        "!cp \"/content/drive/My Drive/\"$image_file \".\"\n",
        "!ls\n",
        "\n",
        "# OTHERWISE, the Image file is supposed to simply be in same directory as the notebook\n",
        "#\n",
        "plt.imshow(matplotlib.image.imread(image_file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9QpEvoeG96Kj",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# Apply YOLO_v3 on image_file, and display the visual objects detection result\n",
        "#\n",
        "!cd pytorch-yolo-v3 && python detect.py --weights ../yolov3.weights --confidence 0.5 --images ../$image_file --det ..\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.title('With confidence_threshold=0.5')\n",
        "plt.imshow(matplotlib.image.imread('det_%s' % image_file))\n",
        "\n",
        "# Same with very low confidence threshold (--> better sensitivity, but lower specificity)\n",
        "#\n",
        "!cd pytorch-yolo-v3 && python detect.py --weights ../yolov3.weights --confidence 0.1 --images ../$image_file --det ..\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.title('With confidence_threshold=0.1')\n",
        "plt.imshow(matplotlib.image.imread('det_%s' % image_file))\n",
        "\n",
        "# Same with very high confidence threshold (--> better specificity but lower sensitivity)\n",
        "#\n",
        "!cd pytorch-yolo-v3 && python detect.py --weights ../yolov3.weights --confidence 0.9 --images ../$image_file --det ..\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.title('With confidence_threshold=0.9')\n",
        "plt.imshow(matplotlib.image.imread('det_%s' % image_file))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frEI3JVVF9j_",
        "colab_type": "text"
      },
      "source": [
        "#### Now, check experimentally the influence of the confidence threshold, and of other detection parameters: NMS Threshhold, input resolution, scales (check out the source code of detect.py to find how they can be modified just by just adding or changing arguments used) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFOthdc7F9kA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rVw92tZ8GzNn"
      },
      "source": [
        "### Same test on an image from CARLA driving simulator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0IAop5ptGsMI",
        "colab": {}
      },
      "source": [
        "image_file = 'example_front-imageCARLA.png'\n",
        "\n",
        "# Uncomment below ONLY IF RUNNING ON Colab, and if the test image is on your GoogleDrive\n",
        "!cp \"/content/drive/My Drive/\"$image_file \".\"\n",
        "!ls\n",
        "\n",
        "# OTHERWISE, the Image file is supposed to simply be in same directory as the notebook\n",
        "#\n",
        "\n",
        "plt.imshow(matplotlib.image.imread(image_file))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPWt5cyFF9kH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply YOLO_v3 on image_file, and display the visual objects detection result\n",
        "#\n",
        "!cd pytorch-yolo-v3 && python detect.py --weights ../yolov3.weights --confidence 0.5 --images ../$image_file --det ..\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(matplotlib.image.imread('det_%s' % image_file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acOT7YUZF9kL",
        "colab_type": "text"
      },
      "source": [
        "#### Now, check experimentally the influence of the confidence threshold, and of other detection parameters: NMS Threshhold, input resolution, scales (check out the source code of detect.py to find how they can be modified just by just adding or changing arguments used) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbVxOfhPF9kL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUs2UfyTLO7R",
        "colab_type": "text"
      },
      "source": [
        "####**[Optional] Train/fine-tune YOLOv3 for detection of other types of objects**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXhSSf1QLzx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}